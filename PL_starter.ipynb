{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 16 10:26:22 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.100      Driver Version: 440.100      CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN X (Pascal)    Off  | 00000000:05:00.0 Off |                  N/A |\n",
      "| 28%   49C    P8    17W / 250W |     10MiB / 12194MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN X (Pascal)    Off  | 00000000:06:00.0 Off |                  N/A |\n",
      "| 25%   44C    P8    11W / 250W |     10MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN X (Pascal)    Off  | 00000000:09:00.0 Off |                  N/A |\n",
      "| 32%   49C    P0    59W / 250W |      0MiB / 12196MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN X (Pascal)    Off  | 00000000:0A:00.0 Off |                  N/A |\n",
      "| 26%   44C    P0    56W / 250W |      0MiB / 12196MiB |      2%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "True\n",
      "4\n",
      "1.6.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorboard==1.15\n",
    "!nvidia-smi\n",
    "gpus= \"0,1,2,3\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= gpus;\n",
    "\n",
    "import torch\n",
    "gpu_count = torch.cuda.device_count()\n",
    "print(torch.cuda.is_available())\n",
    "print(gpu_count)\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threholding(inputs,value):\n",
    "    result = inputs.copy()\n",
    "    print(np.unique(result))\n",
    "    result[result<value]=0\n",
    "    result[result!=value]=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from argparse import ArgumentParser, Namespace\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "class SegModel(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Semantic Segmentation Module\n",
    "    This is a basic semantic segmentation module implemented with Lightning.\n",
    "    It uses CrossEntropyLoss as the default loss function. May be replaced with\n",
    "    other loss functions as required.\n",
    "    It is specific to KITTI dataset i.e. dataloaders are for KITTI\n",
    "    and Normalize transform uses the mean and standard deviation of this dataset.\n",
    "    It uses the FCN ResNet50 model as an example.\n",
    "    Adam optimizer is used along with Cosine Annealing learning rate scheduler.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "#         self.batch_size = hparams.batch_size\n",
    "#         self.lr = hparams.lr\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "        self.loss = loss\n",
    "#         self.save_hyperparameters()  \n",
    "        self.metric = pl.metrics.F1()\n",
    "        self.net = net\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch['data']\n",
    "        y = batch['seg']\n",
    "        x = x.float()\n",
    "        y = y.float()\n",
    "            \n",
    "        y_hat = self(x) #deepSup\n",
    "        loss= self.loss(y_hat,y)\n",
    "        metric = self.metric(y_hat,y)\n",
    "        \n",
    "        if batch_idx==0:\n",
    "            x = x[0].squeeze().cpu().detach().numpy()*255\n",
    "            y = y[0].squeeze().cpu().detach().numpy()*255\n",
    "            y_hat = y_hat[0].squeeze().cpu().detach().numpy().round()*255\n",
    "            x = np.moveaxis(x,0,-1)\n",
    "\n",
    "            \n",
    "#             x = x[0]\n",
    "#             fig, ax = plt.subplots(figsize=(16, 12))\n",
    "#             ax.imshow(x)\n",
    "#             ax.imshow(y,alpha=0.2)\n",
    "#             neptune_logger.experiment.log_image('train', fig)\n",
    "            image = np.hstack([x[...,0],y,y_hat])\n",
    "            neptune_logger.log_image('image_train', image)\n",
    "#             wandb.log({'Train':[wandb.Image(x, masks={\n",
    "#                                                     \"prediction\" : {\"mask_data\" : pred, \"class_labels\" : class_labels},\n",
    "#                                                     \"ground truth\" : {\"mask_data\" : y, \"class_labels\" : class_labels }\n",
    "#                                                     })]\n",
    "#                       })\n",
    "        \n",
    "        result = pl.TrainResult(loss)\n",
    "        result.log('train_loss', loss, on_epoch=True)\n",
    "        result.log('train_acc', metric, on_epoch=True)\n",
    "        \n",
    "        return result\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = batch['data']\n",
    "        y = batch['seg']\n",
    "        x = x.float()\n",
    "        y = y.float()\n",
    "        y_hat = self(x) #deepSup        \n",
    "        loss = self.loss(y_hat,y)\n",
    "        metric = self.metric(y_hat,y)\n",
    "        \n",
    "        if batch_idx==0:\n",
    "            x = x[0].squeeze().cpu().detach().numpy()*255\n",
    "            y = y[0].squeeze().cpu().detach().numpy()*255\n",
    "            y_hat = y_hat[0].squeeze().cpu().detach().numpy().round()*255\n",
    "            x = np.moveaxis(x,0,-1)\n",
    "            \n",
    "            image = np.hstack([x[...,0],y,y_hat])\n",
    "            neptune_logger.log_image('image_valid', image)\n",
    "            \n",
    "#         if batch_idx==0:\n",
    "#             x = x[0].squeeze().cpu().detach().numpy()\n",
    "#             y = y[0].squeeze().cpu().detach().numpy()\n",
    "#             pred = pred[0].squeeze().cpu().detach().numpy().round()\n",
    "#             x = np.moveaxis(x,0,-1)\n",
    "\n",
    "#             wandb.log({'Valid':[wandb.Image(x, masks={\n",
    "#                                                     \"prediction\" : {\"mask_data\" : pred, \"class_labels\" : class_labels},\n",
    "#                                                     \"ground truth\" : {\"mask_data\" : y, \"class_labels\" :class_labels }\n",
    "#                       })]\n",
    "#                       })\n",
    "            \n",
    "        result = pl.EvalResult(checkpoint_on=loss)\n",
    "        result.log('val_loss', loss, on_epoch=True)\n",
    "        result.log('val_acc', metric, on_epoch=True)\n",
    "        return result\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x = batch['data']\n",
    "        y = batch['seg']\n",
    "        fname = batch['fname']\n",
    "        x = x.float()\n",
    "        y = y.float()\n",
    "\n",
    "#         y_hat = self(x) #deepSup        \n",
    "        \n",
    "#         from monai.inferers import SlidingWindowInferer\n",
    "        \n",
    "#         net = self.net\n",
    "#         infer = SlidingWindowInferer(roi_size=(512, 512), sw_batch_size=1, overlap=0.75)\n",
    "#         class ToyModel:\n",
    "#             pred = 0\n",
    "#             def __call__(self, input):\n",
    "#                 input = net(input)\n",
    "#         return input\n",
    "    \n",
    "#         y_hat = infer(x, ToyModel())\n",
    "#         print(y_hat.shape)\n",
    "        \n",
    "        y_hat = pred_tta_seg(net,x,512,100)\n",
    "        loss = self.loss(y_hat,y)\n",
    "        metric = self.metric(y_hat,y)\n",
    "        \n",
    "        for idx_ in range(len(y_hat)):\n",
    "            path =\"Output/\"+fname[idx_].split('/')[-1]\n",
    "            \n",
    "            x = x[idx_].cpu().detach().numpy()\n",
    "            y = y[idx_].cpu().detach().numpy()\n",
    "            \n",
    "            # stack y and result\n",
    "            print(y_hat.shape,np.unique(y_hat))\n",
    "            output = y_hat[idx_].cpu().detach().numpy().round()\n",
    "#             output = np.hstack((np.expand_dims(x[2],0),y,output))   # stack 해서 저장하기!\n",
    "            output = np.moveaxis(output,0,-1)            \n",
    "            skimage.io.imsave(path,output)\n",
    "            \n",
    "        result = pl.EvalResult(checkpoint_on=loss)\n",
    "        result.log('test_loss', loss)\n",
    "        result.log('test_acc', metric)\n",
    "        print(metric)\n",
    "        return result\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt = torch.optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "        sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=10)\n",
    "        return [opt], [sch]\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(train_dataset, shuffle=True, batch_size=self.batch_size) \n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(valid_dataset, shuffle=False, batch_size=self.batch_size) \n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(test_dataset, shuffle=False, batch_size=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "62 62 12 12 100 0\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U git+https://github.com/albu/albumentations\n",
    "import albumentations as albu\n",
    "\n",
    "def augmentation_train():\n",
    "    train_transform = [\n",
    "        albu.HorizontalFlip(p=0.5),\n",
    "        albu.VerticalFlip(p=0.5),\n",
    "        albu.CLAHE(clip_limit=(3,3), tile_grid_size=(4, 4),p=1),\n",
    "        albu.MultiplicativeNoise(multiplier=(0.9, 1.1), per_channel=True, p=1),\n",
    "        albu.RandomBrightnessContrast(brightness_limit=(-0.2, 0.2),contrast_limit=(-0.2, 0.2),brightness_by_max=True, p=0.5),\n",
    "        albu.RandomGamma(gamma_limit=(80,120), p=0.5),\n",
    "#         albu.RandomShadow(p=0.5),\n",
    "        \n",
    "        albu.OneOf([\n",
    "        albu.ElasticTransform(border_mode=cv2.BORDER_CONSTANT,interpolation=cv2.INTER_LINEAR,alpha=1,sigma=50,alpha_affine=50, p=0.5),\n",
    "        albu.GridDistortion(border_mode=cv2.BORDER_CONSTANT,interpolation=cv2.INTER_LINEAR,distort_limit=(-0.2,0.2),num_steps=5, p=0.5),\n",
    "        albu.OpticalDistortion(border_mode=cv2.BORDER_CONSTANT,interpolation=cv2.INTER_LINEAR,distort_limit=(-.05,.05),shift_limit=(-0.05,0.05), p=0.5),\n",
    "        ]\n",
    "        ,p=0.5),\n",
    "        \n",
    "        albu.OneOf([            \n",
    "        albu.IAASharpen(alpha=(0,0.3), lightness=(0.01,0.05), p=0.3),\n",
    "        albu.GaussianBlur(blur_limit=(3), p=0.1),\n",
    "#         albu.MotionBlur(blur_limit=(3), p=0.1),\n",
    "        ],p=0.5),\n",
    "        \n",
    "#         albu.Resize(height=1024, width=1024, always_apply=True),        \n",
    "#         albu.ShiftScaleRotate(border_mode=cv2.BORDER_CONSTANT, interpolation=cv2.INTER_LINEAR, shift_limit=0.1, scale_limit=0.2, rotate_limit=10, p=0.5),\n",
    "        albu.RandomResizedCrop(height=512, width=512, scale=(0.1,0.3),ratio=(.8,1.2), interpolation=cv2.INTER_LINEAR, always_apply=True), \n",
    "#         albu.RandomCrop(height=512, width=512, always_apply=True), \n",
    "\n",
    "        albu.ToGray(p=1)\n",
    "\n",
    "    ]\n",
    "    return albu.Compose(train_transform)\n",
    "\n",
    "def augmentation_valid(center=None):\n",
    "    test_transform = [\n",
    "#         albu.Resize(height=1024, width=1024, always_apply=True),        \n",
    "#         albu.RandomCrop(height=512, width=512, always_apply=True), \n",
    "        albu.CLAHE(clip_limit=(3,3), tile_grid_size=(4, 4),p=1),\n",
    "        albu.RandomResizedCrop(height=512, width=512, scale=(0.1,0.3),ratio=(.8,1.2), interpolation=cv2.INTER_LINEAR, always_apply=True), \n",
    "        albu.ToGray(p=1)\n",
    "        \n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "def augmentation_test(center=None):\n",
    "    test_transform = [\n",
    "        albu.Resize(height=1024, width=1024, always_apply=True),        \n",
    "#         albu.RandomCrop(height=512, width=512, always_apply=True), \n",
    "        albu.CLAHE(clip_limit=(3,3), tile_grid_size=(4, 4),p=1),\n",
    "#         albu.RandomResizedCrop(height=512, width=512, scale=(0.1,0.3),ratio=(.8,1.2), interpolation=cv2.INTER_LINEAR, always_apply=True), \n",
    "        albu.ToGray(p=1)\n",
    "        \n",
    "    ]\n",
    "    return albu.Compose(test_transform)\n",
    "\n",
    "import skimage\n",
    "from skimage.morphology import erosion, dilation, closing, disk\n",
    "from skimage import exposure\n",
    "from skimage import morphology\n",
    "from skimage.measure import label, regionprops\n",
    "\n",
    "# !sudo pip install --upgrade https://github.com/VincentStimper/mclahe/archive/numpy.zip\n",
    "# import mclahe as mc\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def image_mchahe_3ch(image,imagetype='numpy'):\n",
    "    \"\"\"\n",
    "    Input : H x W x C or C x H x W image\n",
    "    \"\"\"\n",
    "    result = np.zeros_like(image)\n",
    "    if imagetype=='numpy':\n",
    "        result[...,0] = mc.mclahe(image[...,0])\n",
    "        result[...,1] = mc.mclahe(image[...,1])\n",
    "        result[...,2] = mc.mclahe(image[...,2])\n",
    "    else:\n",
    "        result[0] = mc.mclahe(image[0])\n",
    "        result[1] = mc.mclahe(image[1])\n",
    "        result[2] = mc.mclahe(image[2])\n",
    "    return result\n",
    "\n",
    "from skimage import data, io, filters\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import feature\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.morphology import square\n",
    "import scipy\n",
    "\n",
    "class Dataset_npy():#DataLoader):\n",
    "    def __init__(self, x_list, y_list, augmentation=None):\n",
    "        self.x_list = x_list\n",
    "        self.y_list = y_list\n",
    "        self.augmentation = augmentation\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x_list)\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        try:\n",
    "            image = np.load(self.x_list[index])\n",
    "        except:\n",
    "            image = cv2.imread(self.x_list[index])\n",
    "#             image = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "#             image = np.expand_dims(image,-1)\n",
    "            image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "#             image = cv2.cvtColor(image,cv2.COLOR_BGR2HSV)\n",
    "        try:\n",
    "            gt_seg = cv2.imread(self.y_list[index],0).astype(np.float32)\n",
    "        except:\n",
    "            gt_seg = np.zeros((image.shape[1],image.shape[2])).astype(np.float32)\n",
    "        \n",
    "        gt_seg[gt_seg!=0] = 1      \n",
    "        gt_seg[gt_seg!=1] = 0\n",
    "        \n",
    "        gt_seg = np.expand_dims(gt_seg,-1)\n",
    "        \n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image = image, mask = gt_seg)\n",
    "            image, gt_seg = sample['image'], sample['mask']\n",
    "        \n",
    "        if np.any(gt_seg):\n",
    "            gt = np.array([1]).astype(np.float32)\n",
    "        else:\n",
    "            gt = np.array([0]).astype(np.float32)\n",
    "\n",
    "        image = np.moveaxis(image/255,-1,0)\n",
    "        gt_seg = np.moveaxis(gt_seg,-1,0)\n",
    "#         gt_seg = np.squeeze(gt_seg).astype(np.long)\n",
    "        return {\"data\":image, \"seg\":gt_seg, \"cls\":gt, \"fname\":self.x_list[index]}       \n",
    "    \n",
    "# !sudo rm -r Mytorch\n",
    "# !sudo rm -r Keeplearning\n",
    "\n",
    "# !sudo git clone https://github.com/kevinkwshin/Mytorch.git\n",
    "# !sudo git clone https://github.com/kevinkwshin/Keeplearning.git\n",
    "    \n",
    "# !sudo pip install -r Mytorch/requirements.txt --quiet\n",
    "\n",
    "# import Mytorch\n",
    "# from Mytorch.unet3plus.UNet_3Plus import *\n",
    "# from Mytorch.__init__ import *\n",
    "\n",
    "import Keeplearning\n",
    "from Keeplearning.image_processing import *\n",
    "from Keeplearning.list_processing import *\n",
    "from Keeplearning.load_data import *\n",
    "from Keeplearning.metrics import *\n",
    "from Keeplearning.visualize import *\n",
    "\n",
    "import wandb\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "path_image_hrf='../dataset/retina_hrf/image/'\n",
    "path_label_hrf='../dataset/retina_hrf/artery_vein_segmentation/'\n",
    "path_image_asan='../dataset/ASAN/retina_20200921/'\n",
    "path_label_asan='../dataset/ASAN/labeling_20200921/'\n",
    "\n",
    "x_list_hrf  = sorted(glob.glob(path_image_hrf+'*'))\n",
    "x_list_asan = sorted(glob.glob(path_image_asan+'*'))\n",
    "y_list_hrf = sorted(glob.glob(path_label_hrf+'*'))\n",
    "y_list_asan = sorted(glob.glob(path_label_asan+'*'))\n",
    "\n",
    "x_train = x_list_hrf[:35] + x_list_asan[:27] \n",
    "y_train = y_list_hrf[:35] + y_list_asan[:27]\n",
    "x_valid = x_list_hrf[35:42] + x_list_asan[27:32]\n",
    "y_valid = y_list_hrf[35:42] + y_list_asan[27:32]\n",
    "x_test = x_list_hrf[42:] + x_list_asan[32:]\n",
    "y_test = y_list_hrf[42:] + y_list_asan[32:]\n",
    "\n",
    "path_image='../dataset/ASAN_100_forLabel/'\n",
    "path_label='../dataset/ASAN_100_forLabel/label/'\n",
    "x_list=list_sort_nicely(glob.glob(path_image+'*'))\n",
    "y_list=list_sort_nicely(glob.glob(path_label+'*'))\n",
    "\n",
    "# path_image='../../retina_for_GAN_fractal_dim/'\n",
    "# path_label='../../retina_for_GAN_fractal_dimss/'\n",
    "# x_list=list_sort_nicely(glob.glob(path_image+'*'))\n",
    "# y_list=list_sort_nicely(glob.glob(path_label+'*'))\n",
    "\n",
    "x_test = x_list\n",
    "y_test = y_list\n",
    "\n",
    "print(len(x_train),len(y_train),len(x_valid),len(y_valid),len(x_test),len(y_test))\n",
    "\n",
    "batch_size = 1\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "train_dataset = Dataset_npy(x_train,y_train,\n",
    "                            augmentation=augmentation_train()\n",
    "                            )\n",
    "\n",
    "valid_dataset = Dataset_npy(x_valid,y_valid,\n",
    "                            augmentation=augmentation_valid()\n",
    "                            )\n",
    "\n",
    "test_dataset = Dataset_npy(x_test,y_test,\n",
    "                            augmentation=augmentation_test(),\n",
    "                            )\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=2,\n",
    "                          shuffle=True,\n",
    "                         )\n",
    "\n",
    "# import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "batch_size = 1\n",
    "\n",
    "valid_loader = DataLoader(valid_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=0,\n",
    "#                           shuffle=True,\n",
    "                         )\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          num_workers=0,\n",
    "#                           shuffle=True,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BoundaryLoss(nn.Module):\n",
    "    \"\"\"Boundary Loss proposed in:\n",
    "    Alexey Bokhovkin et al., Boundary Loss for Remote Sensing Imagery Semantic Segmentation\n",
    "    https://arxiv.org/abs/1905.07852\n",
    "    we set θ0 to 3 and θ to 5-7 as a proper choice\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, theta0=3, theta=5, dims=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.theta0 = theta0\n",
    "        self.theta = theta\n",
    "        self.dims = dims\n",
    "\n",
    "    def forward(self, pred, gt):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "            - pred: the output from model (after softmax)\n",
    "                    shape (N, C, H, W)\n",
    "            - gt: ground truth map , float type\n",
    "                    shape (N, C, H, w)\n",
    "        Return:\n",
    "            - boundary loss, averaged over mini-batch\n",
    "        \"\"\"\n",
    "#         n, c, _, _ = pred.shape\n",
    "        n = pred.shape[0]\n",
    "        c = pred.shape[1]\n",
    "\n",
    "        # one-hot vector of ground truth\n",
    "        one_hot_gt = gt #one_hot(gt, c)\n",
    "\n",
    "        # boundary map\n",
    "        gt_b = F.max_pool2d(1 - one_hot_gt, kernel_size=self.theta0, stride=1, padding=(self.theta0 - 1) // 2)\n",
    "        gt_b -= 1 - one_hot_gt\n",
    "\n",
    "        pred_b = F.max_pool2d(1 - pred, kernel_size=self.theta0, stride=1, padding=(self.theta0 - 1) // 2)\n",
    "        pred_b -= 1 - pred\n",
    "\n",
    "        # extended boundary map\n",
    "        gt_b_ext = F.max_pool2d(gt_b, kernel_size=self.theta, stride=1, padding=(self.theta - 1) // 2)\n",
    "        pred_b_ext = F.max_pool2d(pred_b, kernel_size=self.theta, stride=1, padding=(self.theta - 1) // 2)\n",
    "     \n",
    "        # reshape\n",
    "        gt_b = gt_b.view(n, c, -1)\n",
    "        pred_b = pred_b.view(n, c, -1)\n",
    "        gt_b_ext = gt_b_ext.view(n, c, -1)\n",
    "        pred_b_ext = pred_b_ext.view(n, c, -1)\n",
    "\n",
    "        # Precision, Recall\n",
    "        P = torch.sum(pred_b * gt_b_ext, dim=2) / (torch.sum(pred_b, dim=2) + 1e-7)\n",
    "        R = torch.sum(pred_b_ext * gt_b, dim=2) / (torch.sum(gt_b, dim=2) + 1e-7)\n",
    "\n",
    "        # Boundary F1 Score\n",
    "        BF1 = 2 * P * R / (P + R + 1e-7)\n",
    "\n",
    "        # summing BF1 Score for each class and average over mini-batch\n",
    "        loss = torch.mean(1 - BF1)\n",
    "\n",
    "        return loss    \n",
    "\n",
    "# class BoundaryLoss(nn.Module):\n",
    "#     \"\"\"Boundary Loss proposed in:\n",
    "#     Alexey Bokhovkin et al., Boundary Loss for Remote Sensing Imagery Semantic Segmentation\n",
    "#     https://arxiv.org/abs/1905.07852\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, theta0=3, theta=5, dims=4):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.theta0 = theta0\n",
    "#         self.theta = theta\n",
    "#         self.dims = dims\n",
    "\n",
    "#     def forward(self, pred, gt):\n",
    "#         \"\"\"\n",
    "#         Input:\n",
    "#             - pred: the output from model (after softmax)\n",
    "#                     shape (N, C, H, W)\n",
    "#             - gt: ground truth map , float type\n",
    "#                     shape (N, C, H, w)\n",
    "#         Return:\n",
    "#             - boundary loss, averaged over mini-batch\n",
    "#         \"\"\"\n",
    "# #         n, c, _, _ = pred.shape\n",
    "#         n = pred.shape[0]\n",
    "#         c = pred.shape[1]\n",
    "\n",
    "#         # one-hot vector of ground truth\n",
    "#         one_hot_gt = gt #one_hot(gt, c)\n",
    "\n",
    "#         # boundary map\n",
    "#         gt_b = F.max_pool2d(1 - one_hot_gt, kernel_size=self.theta0, stride=1, padding=(self.theta0 - 1) // 2)\n",
    "#         gt_b -= 1 - one_hot_gt\n",
    "\n",
    "#         pred_b = F.max_pool2d(1 - pred, kernel_size=self.theta0, stride=1, padding=(self.theta0 - 1) // 2)\n",
    "#         pred_b -= 1 - pred\n",
    "\n",
    "#         # extended boundary map\n",
    "#         gt_b_ext = F.max_pool2d(gt_b, kernel_size=self.theta, stride=1, padding=(self.theta - 1) // 2)\n",
    "#         pred_b_ext = F.max_pool2d(pred_b, kernel_size=self.theta, stride=1, padding=(self.theta - 1) // 2)\n",
    "     \n",
    "#         # reshape\n",
    "#         gt_b = gt_b.view(n, c, -1)\n",
    "#         pred_b = pred_b.view(n, c, -1)\n",
    "#         gt_b_ext = gt_b_ext.view(n, c, -1)\n",
    "#         pred_b_ext = pred_b_ext.view(n, c, -1)\n",
    "\n",
    "#         # Precision, Recall\n",
    "#         P = torch.sum(pred_b * gt_b_ext, dim=2) / (torch.sum(pred_b, dim=2) + 1e-7)\n",
    "#         R = torch.sum(pred_b_ext * gt_b, dim=2) / (torch.sum(gt_b, dim=2) + 1e-7)\n",
    "        \n",
    "#         TP = torch.sum(pred_b * gt_b_ext, dim=2)\n",
    "#         FP = torch.sum(pred_b * gt_b, dim=2) \n",
    "#         FN = \n",
    "#         alpha= 0.7\n",
    "        \n",
    "#         # Boundary F1 Score\n",
    "#         BF1 = 2 * P * R / (P + R + 1e-7)\n",
    "\n",
    "#         # summing BF1 Score for each class and average over mini-batch\n",
    "#         loss = torch.mean(1 - BF1)\n",
    "\n",
    "#         return loss    \n",
    "    \n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# def opencv_skelitonize(img):\n",
    "#     skel = np.zeros(img.shape, np.uint8)\n",
    "#     img = img.astype(np.uint8)\n",
    "#     size = np.size(img)\n",
    "#     element = cv2.getStructuringElement(cv2.MORPH_CROSS,(3,3))\n",
    "#     done = False\n",
    "#     while( not done):\n",
    "#         eroded = cv2.erode(img,element)\n",
    "#         temp = cv2.dilate(eroded,element)\n",
    "#         temp = cv2.subtract(img,temp)\n",
    "#         skel = cv2.bitwise_or(skel,temp)\n",
    "#         img = eroded.copy()\n",
    "#         zeros = size - cv2.countNonZero(img)\n",
    "#         if zeros==size:\n",
    "#             done = True\n",
    "#     return skel\n",
    "\n",
    "def dice_loss(pred, target):\n",
    "    '''\n",
    "    inputs shape  (batch, channel, height, width).\n",
    "    calculate dice loss per batch and channel of sample.\n",
    "    E.g. if batch shape is [64, 1, 128, 128] -> [64, 1]\n",
    "    '''\n",
    "    smooth = 1.\n",
    "    N = pred.shape[0]\n",
    "    C = pred.shape[1]\n",
    "    iflat = pred.view(N,C, -1) #batch, channel, -1\n",
    "    tflat = target.view(N,C, -1)\n",
    "    intersection = (iflat * tflat).sum(-1)\n",
    "    return -((2. * intersection + smooth) / (iflat.sum(-1) + tflat.sum(-1) + smooth))\n",
    "\n",
    "# def soft_skeletonize(x, thresh_width=10):\n",
    "# # def soft_skeletonize(x, thresh_width=3):\n",
    "#     '''\n",
    "#     Differenciable aproximation of morphological skelitonization operaton\n",
    "#     thresh_width - maximal expected width of vessel\n",
    "#     '''\n",
    "#     for i in range(thresh_width):\n",
    "#         min_pool_x = torch.nn.functional.max_pool2d(x*-1, (3, 3), 1, 1)*-1\n",
    "#         contour = torch.nn.functional.relu(torch.nn.functional.max_pool2d(min_pool_x, (3, 3), 1, 1) - min_pool_x)\n",
    "#         x = torch.nn.functional.relu(x - contour)\n",
    "#     return x\n",
    "\n",
    "def soft_skeletonize(x, thresh_width = 20):\n",
    "    '''\n",
    "    Differenciable aproximation of morphological skelitonization operaton\n",
    "    thresh_width - maximal expected width of vessel\n",
    "    '''\n",
    "    for i in range(thresh_width):\n",
    "        min_pool_x = torch.nn.functional.max_pool2d(x*-1, (3, 3), 1, 1)*-1\n",
    "        contour = torch.nn.functional.relu(torch.nn.functional.max_pool2d(min_pool_x, (3, 3), 1, 1) - min_pool_x)\n",
    "        x = torch.nn.functional.relu(x - contour)\n",
    "    return x\n",
    "\n",
    "# def norm_intersection(center_line, vessel):\n",
    "#     '''\n",
    "#     inputs shape  (batch, channel, height, width)\n",
    "#     intersection formalized by first ares\n",
    "#     x - suppose to be centerline of vessel (pred or gt) and y - is vessel (pred or gt)\n",
    "#     '''\n",
    "#     smooth = 1.\n",
    "#     clf = center_line.view(*center_line.shape[:2], -1)\n",
    "#     vf = vessel.view(*vessel.shape[:2], -1)\n",
    "#     intersection = (clf * vf).sum(-1)\n",
    "#     return (intersection + smooth) / (clf.sum(-1) + smooth)\n",
    "\n",
    "from skimage.morphology import skeletonize\n",
    "\n",
    "# def soft_cldice_loss(pred, target, target_skeleton=None):\n",
    "#     '''\n",
    "#     inputs shape  (batch, channel, height, width).\n",
    "#     '''\n",
    "#     pred_skeleton = soft_skeletonize(pred)\n",
    "#     if target_skeleton is None:\n",
    "#         target_skeleton = soft_skeletonize(target)\n",
    "        \n",
    "# #     cl_pred = skeletons(pred)\n",
    "# #     if target_skeleton is None:\n",
    "# #         target_skeleton = skeletons(target)    \n",
    "        \n",
    "# #     pred_skeleton = skeletons(pred)\n",
    "# #     target_skeleton = skeletons(target)\n",
    "    \n",
    "#     plt.figure(figsize=(20,20))\n",
    "#     plt.subplot(121)\n",
    "#     plt.imshow(pred_skeleton[0,0])\n",
    "#     plt.subplot(122)\n",
    "#     plt.imshow(target_skeleton[0,0])\n",
    "        \n",
    "#     TP = torch.sum(pred_skeleton*target_skeleton)\n",
    "#     FP = torch.sum(pred_skeleton*(1-target_skeleton))\n",
    "#     FN = torch.sum((1-pred_skeleton)*target_skeleton)\n",
    "    \n",
    "#     return 1 -((2. * TP) / (2*TP + FP + FN))\n",
    "\n",
    "# def soft_cldice_loss(pred, target, target_skeleton=None):\n",
    "#     '''\n",
    "#     inputs shape  (batch, channel, height, width).\n",
    "#     '''\n",
    "# #     cl_pred = soft_skeletonize(pred)\n",
    "# #     if target_skeleton is None:\n",
    "# #         target_skeleton = soft_skeletonize(target)\n",
    "        \n",
    "# #     cl_pred = skeletons(pred)\n",
    "# #     if target_skeleton is None:\n",
    "# #         target_skeleton = skeletons(target)    \n",
    "        \n",
    "#     pred_skeleton = skeletons(pred)\n",
    "#     target_skeleton = skeletons(target)\n",
    "    \n",
    "#     plt.figure(figsize=(20,20))\n",
    "#     plt.subplot(121)\n",
    "#     plt.subplot(122)\n",
    "#     plt.imshow(target_skeleton[0,0])\n",
    "        \n",
    "#     TP = torch.sum(pred_skeleton*target_skeleton)\n",
    "#     FP = torch.sum(pred_skeleton*(1-target_skeleton))\n",
    "#     FN = torch.sum((1-pred_skeleton)*target_skeleton)\n",
    "    \n",
    "#     return 1 -((2. * TP) / (2*TP + FP + FN))\n",
    "\n",
    "def soft_cldice_loss(pred, target, target_skeleton=None):\n",
    "    '''\n",
    "    inputs shape  (batch, channel, height, width).\n",
    "    '''\n",
    "#     cl_pred = soft_skeletonize(pred)\n",
    "#     if target_skeleton is None:\n",
    "#         target_skeleton = soft_skeletonize(target)\n",
    "        \n",
    "#     cl_pred = skeletons(pred)\n",
    "#     if target_skeleton is None:\n",
    "#         target_skeleton = skeletons(target)    \n",
    "        \n",
    "#     pred_skeleton = skeletons(pred.cpu().detach().numpy()).to(device)\n",
    "#     target_skeleton = skeletons(target.cpu().detach().numpy()).to(device)\n",
    "        \n",
    "    pred_skeleton = skeletons(pred.cpu().detach().numpy())#.to(device)\n",
    "    target_skeleton = skeletons(target.cpu().detach().numpy())#.to(device)\n",
    "    \n",
    "#     plt.figure(figsize=(20,20))\n",
    "#     plt.subplot(121)\n",
    "#     plt.imshow(pred_skeleton[0,0])\n",
    "#     plt.subplot(122)\n",
    "#     plt.imshow(target_skeleton[0,0])\n",
    "        \n",
    "    TP = torch.sum(pred_skeleton*target_skeleton)\n",
    "    FP = torch.sum(pred_skeleton*(1-target_skeleton))\n",
    "    FN = torch.sum((1-pred_skeleton)*target_skeleton)\n",
    "    \n",
    "    return 1 -((2. * TP + 1) / (2*TP + FP + FN + 1))\n",
    "\n",
    "# def soft_cldice_loss(pred, target, target_skeleton=None):\n",
    "#     '''\n",
    "#     inputs shape  (batch, channel, height, width).\n",
    "#     calculate clDice loss\n",
    "#     Because pred and target at moment of loss calculation will be a torch tensors\n",
    "#     it is preferable to calculate target_skeleton on the step of batch forming,\n",
    "#     when it will be in numpy array format by means of opencv\n",
    "#     '''\n",
    "# #     cl_pred = soft_skeletonize(pred)\n",
    "# #     if target_skeleton is None:\n",
    "# #         target_skeleton = soft_skeletonize(target)\n",
    "        \n",
    "# #     cl_pred = skeletons(pred)\n",
    "# #     if target_skeleton is None:\n",
    "# #         target_skeleton = skeletons(target)    \n",
    "        \n",
    "#     cl_pred = skeletons(pred.cpu().detach().numpy()).to(device)\n",
    "#     target_skeleton = skeletons(target.cpu().detach().numpy()).to(device)\n",
    "    \n",
    "#     plt.figure(figsize=(20,20))\n",
    "#     plt.subplot(121)\n",
    "#     plt.imshow(cl_pred[0,0])\n",
    "#     plt.subplot(122)\n",
    "#     plt.imshow(target_skeleton[0,0])\n",
    "        \n",
    "#     iflat = norm_intersection(cl_pred, target)\n",
    "#     tflat = norm_intersection(target_skeleton, pred)\n",
    "#     intersection = iflat * tflat\n",
    "#     return -((2. * intersection) / (iflat + tflat))\n",
    "\n",
    "class clDiceLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, pred, gt):\n",
    "        return soft_cldice_loss(pred,gt).squeeze()\n",
    "\n",
    "def skeletons(mask):\n",
    "    \n",
    "    '''\n",
    "    mask shape\n",
    "    batch,channel,height,width    \n",
    "    '''\n",
    "    \n",
    "    shape = mask.shape\n",
    "    result = np.zeros_like(mask)\n",
    "    \n",
    "    for idx in range(shape[0]):\n",
    "        result[idx,0] = dilation(skeletonize(mask[idx,0]),square(2))\n",
    "        # 클러스터 없애기...\n",
    "    return torch.tensor(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install monai\n",
    "from monai.losses import DiceLoss\n",
    "from monai.losses import GeneralizedDiceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class compoundloss(nn.Module):\n",
    "    \"\"\"\n",
    "    TODO : activation\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, list_loss, activation=None, weight=None):\n",
    "        super().__init__()\n",
    "        self.weight=weight\n",
    "        self.list_loss=list_loss\n",
    "            \n",
    "    def forward(self, pr, gt):\n",
    "        \n",
    "        if self.weight == None:\n",
    "            self.weight = torch.ones(len(self.list_loss))/len(self.list_loss)\n",
    "            \n",
    "        lossfn = []\n",
    "        for loss in self.list_loss:\n",
    "            temp = loss\n",
    "            lossfn.append(temp)\n",
    "            \n",
    "        loss = 0\n",
    "        \n",
    "        for idx in range(len(lossfn)):\n",
    "            loss += lossfn[idx](pr,gt) * self.weight[idx]\n",
    "\n",
    "        return torch.mean(loss)\n",
    "    \n",
    "# loss = compoundloss([BoundaryLoss(),clDiceLoss(),Mytorch.utils.losses.DiceLoss()],[.33,.33,.33])\n",
    "loss = compoundloss([BoundaryLoss(),GeneralizedDiceLoss()],[.7,.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/qubvel/segmentation_models.pytorch\n",
    "import segmentation_models_pytorch as smp\n",
    "# model = smp.Unet('timm-efficientnet-b5', classes=1, activation='sigmoid')\n",
    "# net = smp.Unet('timm-efficientnet-b7', classes=1, activation='sigmoid')\n",
    "net = smp.FPN('timm-efficientnet-b7',encoder_weights=None, classes=1, activation='sigmoid')\n",
    "# net = smp.FPN('timm-efficientnet-b7', classes=1, activation='sigmoid')\n",
    "# net = smp.DeepLabV3Plus('timm-efficientnet-b5',encoder_weights=None, in_channels=3, classes=1, activation='sigmoid')\n",
    "# net = smp.DeepLabV3Plus('timm-efficientnet-b5', in_channels=3, classes=1, activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "settings\n",
      " {'project_name': 'Retina', 'exam_name': 'FPN_Loss[BoundaryLoss(), GeneralizedDiceLoss()]', 'auto_scale_batch_size': 'power', 'use_amp': 'native', 'gpus': '0,1,2,3', 'loss': compoundloss()}\n",
      "hyperparams\n",
      " {'epochs': 200, 'grad_batches': 1, 'resume': False, 'batch_size': 64, 'lr': 0.001}\n"
     ]
    }
   ],
   "source": [
    "def experiment_name():\n",
    "    exam_name = net.__repr__().split('(')[0]+ \\\n",
    "                '_'+'Loss'+str(loss.list_loss)        \n",
    "    return exam_name \n",
    "\n",
    "exam_name =  experiment_name()\n",
    "# !pip install easydict\n",
    "import easydict\n",
    "\n",
    "settings = easydict.EasyDict({\n",
    "                              \"project_name\":\"Retina\", \n",
    "                              \"exam_name\": exam_name,\n",
    "                              \"auto_scale_batch_size\":'power',\n",
    "                              \"use_amp\":'native',\n",
    "                              \"gpus\": gpus,\n",
    "                              'loss':loss,\n",
    "})\n",
    "\n",
    "hparams = easydict.EasyDict({\n",
    "                          \"epochs\": 200,\n",
    "                          \"grad_batches\":1,\n",
    "                          \"resume\": False,\n",
    "                          \"batch_size\":64,\n",
    "                          \"lr\":0.001,\n",
    "})\n",
    "\n",
    "print('settings\\n',settings)\n",
    "print('hyperparams\\n',hparams)\n",
    "\n",
    "lr = 0.001\n",
    "batch_size = 32\n",
    "model = SegModel(**vars(hparams))\n",
    "\n",
    "# logger = WandbLogger(project=hparams.project_name, name=hparams.exam_name)\n",
    "# logger.watch(model.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import neptune\n",
    "\n",
    "CHECKPOINTS_DIR = 'mymodel/'\n",
    "\n",
    "from pytorch_lightning.loggers.neptune import NeptuneLogger\n",
    "\n",
    "neptune_logger = NeptuneLogger(\n",
    "    api_key=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiZGUwYmNlMTAtYzlmYy00MzAxLTk0MGItM2NmZjUxZGRkZWUzIn0=\",\n",
    "    project_name=\"kevinkwshin/test\",\n",
    "    close_after_fit=True,\n",
    "    experiment_name='logs/'+exam_name,  \n",
    "    params=hparams,\n",
    "    \n",
    "#     upload_source_files=['final_FPN.ipynb']\n",
    "#     params={\"max_epochs\": MAX_EPOCHS,\n",
    "#             \"batch_size\": BATCHSIZE,\n",
    "#             \"lr\": LR},\n",
    ")\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint,EarlyStopping\n",
    "\n",
    "\n",
    "model_checkpoint = pl.callbacks.ModelCheckpoint(filepath=CHECKPOINTS_DIR)\n",
    "\n",
    "# checkpoint_callback = ModelCheckpoint(\n",
    "#     filepath='mymodel/{epoch}-{val_loss:.2f}-{other_metric:.2f}'\n",
    "# )\n",
    "# early_stop_callback = EarlyStopping(monitor='val_loss', verbose=True,)\n",
    "\n",
    "resume_from_checkpoint = 'best.ckpt'\n",
    "\n",
    "trainer = Trainer(max_epochs=200,\n",
    "                  logger=neptune_logger,\n",
    "                  checkpoint_callback=model_checkpoint,\n",
    "                  )\n",
    "trainer.fit(model)\n",
    "# trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_tta_seg(model,image,inference_size=512,tta_time = 100):\n",
    "    \n",
    "    B,C,image_h,image_w = image.shape # (B,C,H,W)\n",
    "    pad_h = inference_size \n",
    "    pad_w = inference_size\n",
    "    \n",
    "    result = (torch.ones(1,1,image_h,image_w)/2)\n",
    "    \n",
    "    h_delta = inference_size//2\n",
    "    w_delta = inference_size//2\n",
    "    \n",
    "    for idx in range(tta_time):\n",
    "\n",
    "        h_center = np.random.randint(h_delta,image_h-h_delta)\n",
    "        w_center = np.random.randint(w_delta,image_w-w_delta)\n",
    "\n",
    "        h1 = - h_delta + h_center\n",
    "        h2 =   h_delta + h_center\n",
    "\n",
    "        w1 = - w_delta + w_center\n",
    "        w2 =   w_delta + w_center\n",
    "    \n",
    "        image_temp = image[:,:,h1:h2,w1:w2]\n",
    "        result_temp = result[:,:,h1:h2,w1:w2]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = model(image_temp)\n",
    "            result_temp = (result_temp+pred)/2\n",
    "            result[:,:,h1:h2,w1:w2] = result_temp\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: False\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace08edf7d2144d094405f2f3d3b9c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.5618488e-18 1.5932064e-18 2.0240830e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [3.3617570e-20 4.5972588e-20 6.4369069e-20 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4966)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [4.6301606e-20 1.2066262e-19 1.2600047e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4974)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [3.9974355e-18 4.4052935e-18 4.7243006e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4958)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [8.0267222e-20 8.2956283e-20 1.1985082e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4969)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [7.0032866e-18 7.4045834e-18 8.0390069e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4968)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.0162541e-17 1.1653781e-17 1.3752970e-17 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4969)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.5824714e-18 2.2002564e-18 3.7538333e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4973)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.4523897e-20 2.6486729e-20 3.4055733e-20 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4968)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [4.5188728e-18 5.9850372e-18 8.1299819e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4973)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.07208735e-16 1.15496794e-16 1.31490999e-16 ... 9.99999881e-01\n",
      " 9.99999940e-01 1.00000000e+00]\n",
      "tensor(0.4969)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [8.3214791e-18 8.9869120e-18 1.1320980e-17 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4966)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [7.2066647e-18 9.0927878e-18 1.1706838e-17 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4971)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [8.2376998e-18 1.2264682e-17 1.6252825e-17 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4962)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [8.3813269e-19 1.0455904e-18 1.0888044e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4969)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.0085317e-21 2.5125038e-21 1.0425048e-20 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.4538923e-17 1.4982456e-17 1.5254546e-17 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4970)\n",
      "torch.Size([1, 1, 1024, 1024]) [2.9250893e-19 1.4450355e-18 1.7983874e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.6243420e-20 1.7489776e-20 1.7831804e-20 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4969)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.8815089e-20 1.9372190e-20 2.0784474e-20 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4973)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [8.0354863e-19 9.2013048e-19 9.5909917e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4971)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.6513801e-17 2.3054278e-17 2.9285456e-17 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [6.9209473e-19 8.5633852e-19 1.4134619e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4972)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [4.4381985e-20 6.8946267e-20 7.4070017e-20 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [3.7090967e-19 4.1983306e-19 6.5179377e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4971)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [5.3140879e-19 5.5417043e-19 5.9582755e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4971)\n",
      "torch.Size([1, 1, 1024, 1024]) [7.4008315e-19 7.7327015e-19 8.1399044e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4972)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.1191236e-17 2.4103950e-17 2.5294298e-17 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4964)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [3.3536284e-18 8.4673003e-18 1.6732611e-17 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.1857334e-18 5.4771992e-18 7.5355864e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4962)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.2128711e-18 2.5075101e-18 3.1983482e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4969)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [4.8192146e-18 4.8266601e-18 4.9611456e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4977)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.5518062e-18 2.6382409e-18 3.1268906e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4968)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.1503879e-18 1.2123170e-18 2.2599815e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4980)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [3.0696910e-19 3.6808514e-19 3.7302007e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4969)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [8.8397401e-19 8.8632010e-19 8.9049633e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4973)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.3564788e-17 1.3903647e-17 1.9075567e-17 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4971)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [3.7564601e-20 3.9941598e-20 4.1425079e-20 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4969)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [7.7687347e-18 1.6497353e-17 1.7010149e-17 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4973)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.1689875e-19 2.1692623e-19 2.1694515e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4971)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [7.9469842e-19 1.2803538e-18 1.4494462e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.0957540e-18 1.3684637e-18 1.7792711e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4968)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [8.4954733e-18 1.3988986e-17 1.8145921e-17 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4961)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [4.3402694e-19 4.6059846e-19 4.6528346e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4963)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [8.29936778e-18 1.21587965e-17 4.76145278e-17 ... 9.99999881e-01\n",
      " 9.99999940e-01 1.00000000e+00]\n",
      "tensor(0.4962)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [4.2758177e-17 4.3040014e-17 4.8680360e-17 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [3.7366627e-18 3.8079495e-18 3.9484660e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [8.8684052e-17 1.3050046e-16 1.3190890e-16 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [3.5671035e-18 3.7111706e-18 3.7582757e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4969)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [3.4744609e-18 3.4756338e-18 3.5036517e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4964)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [7.4174897e-22 8.2891242e-22 8.3940576e-22 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4969)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [3.8729459e-20 5.0502336e-20 5.8686539e-20 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4962)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.3606323e-19 2.9969457e-19 3.2645507e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4966)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.5576179e-19 2.7658547e-19 3.8987261e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4968)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.32019964e-20 1.35744184e-20 3.08420301e-20 ... 9.99999881e-01\n",
      " 9.99999940e-01 1.00000000e+00]\n",
      "tensor(0.4971)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.6940873e-21 1.6940919e-21 1.6941109e-21 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4972)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.3091675e-19 2.3515186e-19 2.3570579e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4965)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [3.6218397e-20 7.7172113e-20 8.7405804e-20 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4969)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.8007084e-18 3.2213159e-18 5.2127996e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4971)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.7103199e-18 2.0842699e-18 2.3201612e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4969)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.0065312e-18 1.1477018e-18 1.1906724e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4961)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [4.7024291e-18 6.3002886e-18 7.2637658e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4961)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.5677294e-21 2.9223027e-21 3.3939334e-21 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.7173969e-19 2.2765740e-19 2.4105361e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4965)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.3974763e-18 2.6161136e-18 2.8690052e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [8.2889379e-18 8.7142700e-18 1.0724375e-17 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4965)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.4703945e-18 2.8809367e-18 3.9005478e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4964)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.4483178e-19 1.8165185e-19 1.9980091e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4962)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [3.2007198e-21 4.4951434e-21 6.1094869e-21 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4968)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.8164782e-18 2.8391537e-18 3.9342335e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4959)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [5.4228759e-20 5.4231880e-20 5.4257213e-20 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4969)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.9902207e-19 3.6375567e-19 4.1347618e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4973)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.9013047e-19 4.5101651e-19 1.2706532e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4963)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [8.6185835e-20 9.5641602e-20 1.0929681e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4972)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.6020883e-18 4.7767567e-18 9.8965601e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4972)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [4.2955851e-20 4.4753932e-20 4.8113797e-20 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4968)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [7.4434825e-21 2.1691952e-20 4.6785836e-20 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [4.1108686e-20 4.4063698e-20 5.5801371e-20 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.6471222e-19 4.3119129e-19 4.6048617e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4966)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [5.9726923e-19 8.2188986e-19 8.6927470e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4961)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.2447457e-20 2.2583163e-20 2.5315431e-20 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4968)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [7.3940899e-21 7.6374248e-21 7.7180709e-21 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4967)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [5.4672983e-19 1.0208051e-18 1.0458083e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.0752501e-21 2.1579900e-21 2.2676692e-21 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4966)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.15189805e-17 1.25724166e-17 1.28804379e-17 ... 9.99999881e-01\n",
      " 9.99999940e-01 1.00000000e+00]\n",
      "tensor(0.4962)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [3.0225428e-20 3.1341033e-20 3.1673625e-20 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4963)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [7.4364196e-20 9.2905488e-20 1.1901150e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4960)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.6485060e-18 2.1502541e-18 2.5837594e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4962)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [5.0416526e-18 6.2694661e-18 7.1960561e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4965)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.1578481e-23 2.2954096e-23 2.5957396e-23 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4964)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.2588191e-18 1.7117997e-18 3.2144789e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4957)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [4.8257593e-18 1.0577495e-17 1.4407460e-17 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4960)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.4217214e-19 2.7364911e-19 2.7386932e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4963)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [2.0197288e-18 2.4087351e-18 2.5925379e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4962)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [8.8112224e-22 9.7579585e-22 1.0055020e-21 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4966)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [3.0484963e-20 4.0199449e-20 4.3995420e-20 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4968)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [1.6090178e-18 1.7438992e-18 1.7532312e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4958)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [5.5815708e-19 6.4477607e-19 1.8472626e-18 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4964)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [4.6391939e-19 5.7068690e-19 7.8449453e-19 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float32 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024, 1024]) [6.2351445e-21 6.7112927e-21 1.6811990e-20 ... 9.9999988e-01 9.9999994e-01\n",
      " 1.0000000e+00]\n",
      "tensor(0.4969)\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'test_acc': tensor(0.4967), 'test_loss': tensor(0.5000)}\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.5, 'test_acc': 0.4967293441295624}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "\n",
    "resume_from_checkpoint = 'mymodel/epoch=73.ckpt'\n",
    "\n",
    "trainer = Trainer(max_epochs=1,\n",
    "                  resume_from_checkpoint=resume_from_checkpoint,\n",
    "#                   gpus=gpus,\n",
    "                  )\n",
    "\n",
    "trainer.test(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.inferers import SlidingWindowInferer\n",
    "\n",
    "class ToyModel:\n",
    "    # A simple model generates the output by adding an integer `pred` to input.\n",
    "    # each call of this instance increases the integer by 1.\n",
    "    pred = 0\n",
    "    def __call__(self, input):\n",
    "        self.pred = self.pred + 1\n",
    "        input = input + self.pred\n",
    "        return input\n",
    "\n",
    "infer = SlidingWindowInferer(roi_size=(512, 512), sw_batch_size=1, overlap=0.75)\n",
    "input_tensor = torch.zeros(1, 3, 1024,1024)\n",
    "output_tensor = infer(input_tensor, ToyModel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output_tensor[0, 0]); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "a = np.random.rand(512,512,3)\n",
    "ax.histmshow(a)\n",
    "neptune_logger.experiment.log_image(epoch, fig)\n",
    "\n",
    "# Get predictions on external test\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# y_true, y_pred = [],[]\n",
    "# for i, (x, y) in enumerate(test_loader):\n",
    "#     y_hat = model.forward(x).argmax(axis=1).cpu().detach().numpy()\n",
    "#     y = y.cpu().detach().numpy()\n",
    "\n",
    "#     y_true.append(y)\n",
    "#     y_pred.append(y_hat)\n",
    "\n",
    "#     if i == len(test_loader):\n",
    "#         break\n",
    "# y_true = np.hstack(y_true)\n",
    "# y_pred = np.hstack(y_pred)\n",
    "\n",
    "# # Log additional metrics\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# accuracy = accuracy_score(y_true, y_pred)\n",
    "# neptune_logger.experiment.log_metric('test_accuracy', accuracy)\n",
    "\n",
    "# # Log charts\n",
    "# from scikitplot.metrics import plot_confusion_matrix\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(16, 12))\n",
    "# plot_confusion_matrix(y_true, y_pred, ax=ax)\n",
    "# neptune_logger.experiment.log_image('confusion_matrix', fig)\n",
    "\n",
    "# # Save checkpoints folder\n",
    "# neptune_logger.experiment.log_artifact(CHECKPOINTS_DIR)\n",
    "\n",
    "# # You can stop the experiment\n",
    "# neptune_logger.experiment.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "neptune": {
   "notebookId": "1b576910-d050-4887-bee9-6e749c6b1150"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
